2025-08-16 12:35:32,071 - INFO - ================================================================================
2025-08-16 12:35:32,071 - INFO - DHP PENDULUM TRAINING SESSION STARTED
2025-08-16 12:35:32,071 - INFO - ================================================================================
2025-08-16 12:35:32,071 - INFO - HYPERPARAMETERS:
2025-08-16 12:35:32,071 - INFO - ----------------------------------------
2025-08-16 12:35:32,071 - INFO - action_size              : 1
2025-08-16 12:35:32,071 - INFO - activation               : tanh
2025-08-16 12:35:32,071 - INFO - best_episode_gui         : False
2025-08-16 12:35:32,072 - INFO - episode_length           : 200
2025-08-16 12:35:32,072 - INFO - excitation_amplitude     : 0.2
2025-08-16 12:35:32,072 - INFO - excitation_steps         : 7500
2025-08-16 12:35:32,072 - INFO - gamma                    : 0.95
2025-08-16 12:35:32,072 - INFO - gui                      : False
2025-08-16 12:35:32,072 - INFO - hidden_layer_size        : [64, 64, 32]
2025-08-16 12:35:32,072 - INFO - log_interval             : 50
2025-08-16 12:35:32,072 - INFO - lr_actor                 : 0.005
2025-08-16 12:35:32,072 - INFO - lr_critic                : 0.01
2025-08-16 12:35:32,072 - INFO - max_steps                : 200
2025-08-16 12:35:32,072 - INFO - normalize_states         : True
2025-08-16 12:35:32,072 - INFO - num_episodes             : 1500
2025-08-16 12:35:32,072 - INFO - predict_delta            : False
2025-08-16 12:35:32,072 - INFO - record                   : False
2025-08-16 12:35:32,072 - INFO - record_best_episodes     : True
2025-08-16 12:35:32,072 - INFO - recording_fps            : 30
2025-08-16 12:35:32,072 - INFO - reference_size           : 2
2025-08-16 12:35:32,072 - INFO - rls_action_size          : 1
2025-08-16 12:35:32,072 - INFO - rls_covariance           : 100.0
2025-08-16 12:35:32,072 - INFO - rls_gamma                : 0.9995
2025-08-16 12:35:32,072 - INFO - rls_state_size           : 2
2025-08-16 12:35:32,072 - INFO - save_interval            : 200
2025-08-16 12:35:32,072 - INFO - split                    : False
2025-08-16 12:35:32,072 - INFO - state_bounds             : {'theta': [-3.141592653589793, 3.141592653589793], 'theta_dot': [-8.0, 8.0]}
2025-08-16 12:35:32,072 - INFO - state_size               : 2
2025-08-16 12:35:32,072 - INFO - target_network           : True
2025-08-16 12:35:32,072 - INFO - tau                      : 0.001
2025-08-16 12:35:32,073 - INFO - update_cycles            : 2
2025-08-16 12:35:32,073 - INFO - ----------------------------------------
2025-08-16 12:35:32,073 - INFO - Log file: /home/osos/Mohamed_Masters_Thesis/DHP_pendulum/training_logs/dhp_pendulum_training_20250816_123532.log
2025-08-16 12:35:32,073 - INFO - ================================================================================
2025-08-16 12:35:32,073 - INFO - 
==================================================
2025-08-16 12:35:32,073 - INFO - STARTING DHP TRAINING FOR PENDULUM
2025-08-16 12:35:32,073 - INFO - ==================================================
2025-08-16 12:35:32,074 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2025-08-16 12:35:32,180 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:100: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2025-08-16 12:35:32,183 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:102: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2025-08-16 12:35:32,187 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:124: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

2025-08-16 12:35:32,187 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:128: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
2025-08-16 12:35:32,187 - WARNING - From /home/osos/anaconda3/envs/DHP/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
2025-08-16 12:35:32,223 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:133: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

2025-08-16 12:35:32,240 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:139: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

2025-08-16 12:35:32,279 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:156: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

2025-08-16 12:35:32,355 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:79: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2025-08-16 12:35:32,356 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:80: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

2025-08-16 12:35:32,374 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:81: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

2025-08-16 12:35:32,449 - INFO - 
Training for 1000 episodes...
2025-08-16 12:35:32,449 - INFO - Episode | Reward  | Avg Cost | Pos Error | Success | Time
2025-08-16 12:35:32,449 - INFO - ------------------------------------------------------------
2025-08-16 12:35:34,146 - INFO -       0 | -6826.14 |    4.775 |    1.7228 |   0.000 |    1.7s
2025-08-16 12:35:37,189 - INFO - CONVERGENCE EPISODE 3: 0.0005 rad
2025-08-16 12:35:37,299 - INFO - CONVERGENCE EPISODE 4: 0.0030 rad
2025-08-16 12:35:44,854 - INFO - CONVERGENCE EPISODE 10: 0.0009 rad
2025-08-16 12:35:52,583 - INFO - CONVERGENCE EPISODE 16: 0.0022 rad
2025-08-16 12:35:52,616 - INFO - CONVERGENCE EPISODE 17: 0.0010 rad
2025-08-16 12:36:05,316 - INFO -      25 | -7034.53 |    4.922 |    1.6451 |   0.000 |   32.9s
2025-08-16 12:36:11,315 - INFO - CONVERGENCE EPISODE 30: 0.0002 rad
2025-08-16 12:36:30,588 - INFO - CONVERGENCE EPISODE 44: 0.0018 rad
2025-08-16 12:36:39,686 - INFO -      50 | -6647.93 |    4.601 |    1.8136 |   0.000 |   67.2s
2025-08-16 12:36:54,749 - INFO - CONVERGENCE EPISODE 61: 0.0026 rad
2025-08-16 12:36:54,768 - INFO - CONVERGENCE EPISODE 62: 0.0017 rad
2025-08-16 12:37:05,266 - INFO - CONVERGENCE EPISODE 69: 0.1853 rad
2025-08-16 12:37:14,287 - INFO -      75 | -6555.93 |   10.392 |    0.7811 |   0.000 |  101.8s
2025-08-16 12:37:15,036 - INFO - CONVERGENCE EPISODE 76: 0.0004 rad
2025-08-16 12:37:17,078 - INFO - CONVERGENCE EPISODE 78: 0.0012 rad
2025-08-16 12:37:18,642 - INFO - CONVERGENCE EPISODE 80: 0.0005 rad
2025-08-16 12:37:21,643 - INFO - CONVERGENCE EPISODE 82: 0.4824 rad
2025-08-16 12:37:23,166 - INFO - CONVERGENCE EPISODE 83: 0.2049 rad
2025-08-16 12:37:27,672 - INFO - CONVERGENCE EPISODE 86: 0.4829 rad
2025-08-16 12:37:28,848 - INFO - CONVERGENCE EPISODE 87: 0.0028 rad
2025-08-16 12:37:32,376 - INFO - CONVERGENCE EPISODE 90: 0.0022 rad
2025-08-16 12:37:34,325 - INFO - CONVERGENCE EPISODE 91: 0.2130 rad
2025-08-16 12:37:34,343 - INFO - CONVERGENCE EPISODE 92: 0.0011 rad
2025-08-16 12:37:35,442 - INFO - CONVERGENCE EPISODE 93: 0.0004 rad
2025-08-16 12:37:36,940 - INFO - CONVERGENCE EPISODE 94: 0.0028 rad
2025-08-16 12:37:40,386 - INFO - CONVERGENCE EPISODE 96: 0.2798 rad
2025-08-16 12:37:42,066 - INFO - CONVERGENCE EPISODE 97: 0.3004 rad
2025-08-16 12:37:43,817 - INFO - CONVERGENCE EPISODE 98: 0.4754 rad
2025-08-16 12:37:44,379 - INFO - CONVERGENCE EPISODE 99: 0.0018 rad
2025-08-16 12:37:45,552 - INFO - CONVERGENCE EPISODE 100: 0.0031 rad
2025-08-16 12:37:45,552 - INFO - 
2025-08-16 12:37:45,552 - INFO - MILESTONE 100 ANALYSIS:
2025-08-16 12:37:45,552 - INFO -   Recent 50 episodes avg position error: 1.1720 Â± 0.9886 rad
2025-08-16 12:37:45,552 - INFO -   Recent 50 episodes avg cost: 8.038
2025-08-16 12:37:45,552 - INFO -   Recent 50 episodes success rate: 0.00%
2025-08-16 12:37:45,552 - INFO -   Convergent episodes ratio (< 0.5 rad): 40.00%
2025-08-16 12:37:45,552 - INFO -   Total convergent episodes so far: 27
2025-08-16 12:37:45,552 - INFO -   Best performance: 0.0002 rad at episode 30
2025-08-16 12:37:45,552 - INFO -   Stable performance not yet achieved
2025-08-16 12:37:45,552 - INFO - 
2025-08-16 12:37:45,552 - INFO -     100 | -4506.80 |   10.094 |    0.0031 |   0.000 |  133.1s
2025-08-16 12:37:47,437 - INFO - CONVERGENCE EPISODE 101: 0.1511 rad
2025-08-16 12:38:01,886 - INFO - CONVERGENCE EPISODE 109: 0.3554 rad
2025-08-16 12:38:03,816 - INFO - CONVERGENCE EPISODE 110: 0.2903 rad
2025-08-16 12:38:05,143 - INFO - CONVERGENCE EPISODE 111: 0.0023 rad
2025-08-16 12:38:05,260 - INFO - CONVERGENCE EPISODE 112: 0.0024 rad
2025-08-16 12:38:07,818 - INFO - CONVERGENCE EPISODE 114: 0.0006 rad
2025-08-16 12:38:13,864 - INFO - CONVERGENCE EPISODE 118: 0.0025 rad
2025-08-16 12:38:17,931 - INFO - CONVERGENCE EPISODE 120: 0.2820 rad
2025-08-16 12:38:17,992 - INFO - CONVERGENCE EPISODE 121: 0.0005 rad
2025-08-16 12:38:22,043 - INFO - CONVERGENCE EPISODE 124: 0.0014 rad
2025-08-16 12:38:22,084 - INFO - CONVERGENCE EPISODE 125: 0.0009 rad
2025-08-16 12:38:22,084 - INFO -     125 |   -6.58 |    0.492 |    0.0009 |   0.000 |  169.6s
2025-08-16 12:38:31,268 - INFO - CONVERGENCE EPISODE 130: 0.0009 rad
2025-08-16 12:38:35,674 - INFO - CONVERGENCE EPISODE 132: 0.4690 rad
