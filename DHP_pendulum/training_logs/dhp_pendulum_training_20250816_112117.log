2025-08-16 11:21:17,241 - INFO - ================================================================================
2025-08-16 11:21:17,241 - INFO - DHP PENDULUM TRAINING SESSION STARTED
2025-08-16 11:21:17,241 - INFO - ================================================================================
2025-08-16 11:21:17,241 - INFO - HYPERPARAMETERS:
2025-08-16 11:21:17,241 - INFO - ----------------------------------------
2025-08-16 11:21:17,241 - INFO - action_size              : 1
2025-08-16 11:21:17,241 - INFO - activation               : tanh
2025-08-16 11:21:17,241 - INFO - best_episode_gui         : False
2025-08-16 11:21:17,241 - INFO - episode_length           : 200
2025-08-16 11:21:17,241 - INFO - excitation_amplitude     : 0.2
2025-08-16 11:21:17,241 - INFO - excitation_steps         : 7500
2025-08-16 11:21:17,241 - INFO - gamma                    : 0.95
2025-08-16 11:21:17,241 - INFO - gui                      : False
2025-08-16 11:21:17,241 - INFO - hidden_layer_size        : [64, 64, 32]
2025-08-16 11:21:17,241 - INFO - log_interval             : 50
2025-08-16 11:21:17,241 - INFO - lr_actor                 : 0.005
2025-08-16 11:21:17,241 - INFO - lr_critic                : 0.01
2025-08-16 11:21:17,241 - INFO - max_steps                : 200
2025-08-16 11:21:17,241 - INFO - normalize_states         : True
2025-08-16 11:21:17,241 - INFO - num_episodes             : 1500
2025-08-16 11:21:17,242 - INFO - predict_delta            : False
2025-08-16 11:21:17,242 - INFO - record                   : False
2025-08-16 11:21:17,242 - INFO - record_best_episodes     : True
2025-08-16 11:21:17,242 - INFO - recording_fps            : 30
2025-08-16 11:21:17,242 - INFO - reference_size           : 2
2025-08-16 11:21:17,242 - INFO - rls_action_size          : 1
2025-08-16 11:21:17,242 - INFO - rls_covariance           : 100.0
2025-08-16 11:21:17,242 - INFO - rls_gamma                : 0.9995
2025-08-16 11:21:17,242 - INFO - rls_state_size           : 2
2025-08-16 11:21:17,242 - INFO - save_interval            : 200
2025-08-16 11:21:17,242 - INFO - split                    : False
2025-08-16 11:21:17,242 - INFO - state_bounds             : {'theta': [-3.141592653589793, 3.141592653589793], 'theta_dot': [-8.0, 8.0]}
2025-08-16 11:21:17,242 - INFO - state_size               : 2
2025-08-16 11:21:17,242 - INFO - target_network           : True
2025-08-16 11:21:17,242 - INFO - tau                      : 0.001
2025-08-16 11:21:17,242 - INFO - update_cycles            : 2
2025-08-16 11:21:17,242 - INFO - ----------------------------------------
2025-08-16 11:21:17,242 - INFO - Log file: /home/osos/Mohamed_Masters_Thesis/DHP_pendulum/training_logs/dhp_pendulum_training_20250816_112117.log
2025-08-16 11:21:17,242 - INFO - ================================================================================
2025-08-16 11:21:17,242 - INFO - 
==================================================
2025-08-16 11:21:17,242 - INFO - STARTING DHP TRAINING FOR PENDULUM
2025-08-16 11:21:17,242 - INFO - ==================================================
2025-08-16 11:21:17,245 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2025-08-16 11:21:17,365 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:100: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2025-08-16 11:21:17,366 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:102: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2025-08-16 11:21:17,374 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:124: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

2025-08-16 11:21:17,375 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:128: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
2025-08-16 11:21:17,376 - WARNING - From /home/osos/anaconda3/envs/DHP/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
2025-08-16 11:21:17,412 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:133: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

2025-08-16 11:21:17,426 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:139: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

2025-08-16 11:21:17,471 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:156: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

2025-08-16 11:21:17,564 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:79: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2025-08-16 11:21:17,564 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:80: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

2025-08-16 11:21:17,582 - WARNING - From /home/osos/Mohamed_Masters_Thesis/msc-thesis/agents/dhp.py:81: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

2025-08-16 11:21:17,644 - INFO - 
Training for 2500 episodes...
2025-08-16 11:21:17,644 - INFO - Episode | Reward  | Avg Cost | Pos Error | Success | Time
2025-08-16 11:21:17,644 - INFO - ------------------------------------------------------------
2025-08-16 11:21:19,347 - INFO -       0 | -7129.45 | 313686051.597 |    0.8207 |   0.000 |    1.7s
2025-08-16 11:21:39,490 - INFO - CONVERGENCE EPISODE 12: 0.4302 rad
2025-08-16 11:21:41,098 - INFO - CONVERGENCE EPISODE 13: 0.2725 rad
2025-08-16 11:21:41,157 - INFO - CONVERGENCE EPISODE 14: 0.0023 rad
2025-08-16 11:21:42,835 - INFO - CONVERGENCE EPISODE 15: 0.1436 rad
2025-08-16 11:21:43,054 - INFO - CONVERGENCE EPISODE 16: 0.0027 rad
2025-08-16 11:21:44,694 - INFO - CONVERGENCE EPISODE 17: 0.0645 rad
2025-08-16 11:21:45,473 - INFO - CONVERGENCE EPISODE 18: 0.0031 rad
2025-08-16 11:21:45,927 - INFO - CONVERGENCE EPISODE 19: 0.0015 rad
2025-08-16 11:21:46,673 - INFO - CONVERGENCE EPISODE 20: 0.0030 rad
2025-08-16 11:21:47,779 - INFO - CONVERGENCE EPISODE 21: 0.0003 rad
2025-08-16 11:21:47,779 - INFO - STABLE PERFORMANCE ACHIEVED starting at episode 12
2025-08-16 11:21:47,838 - INFO - CONVERGENCE EPISODE 22: 0.0028 rad
2025-08-16 11:21:48,479 - INFO - CONVERGENCE EPISODE 23: 0.0028 rad
2025-08-16 11:21:49,022 - INFO - CONVERGENCE EPISODE 24: 0.0006 rad
2025-08-16 11:21:49,493 - INFO - CONVERGENCE EPISODE 25: 0.0017 rad
2025-08-16 11:21:49,617 - INFO - CONVERGENCE EPISODE 26: 0.0031 rad
2025-08-16 11:21:50,090 - INFO - CONVERGENCE EPISODE 27: 0.0014 rad
2025-08-16 11:21:50,561 - INFO - CONVERGENCE EPISODE 28: 0.0030 rad
2025-08-16 11:21:52,153 - INFO - CONVERGENCE EPISODE 29: 0.0329 rad
2025-08-16 11:21:52,924 - INFO - CONVERGENCE EPISODE 30: 0.0010 rad
2025-08-16 11:21:53,374 - INFO - CONVERGENCE EPISODE 31: 0.0016 rad
2025-08-16 11:21:54,059 - INFO - CONVERGENCE EPISODE 32: 0.0026 rad
2025-08-16 11:21:54,457 - INFO - CONVERGENCE EPISODE 33: 0.0027 rad
2025-08-16 11:21:54,834 - INFO - CONVERGENCE EPISODE 34: 0.0024 rad
2025-08-16 11:21:55,205 - INFO - CONVERGENCE EPISODE 35: 0.0010 rad
2025-08-16 11:21:55,332 - INFO - CONVERGENCE EPISODE 36: 0.0023 rad
2025-08-16 11:21:56,338 - INFO - CONVERGENCE EPISODE 37: 0.0005 rad
2025-08-16 11:21:57,069 - INFO - CONVERGENCE EPISODE 38: 0.0009 rad
2025-08-16 11:21:57,803 - INFO - CONVERGENCE EPISODE 39: 0.0027 rad
2025-08-16 11:21:59,030 - INFO - CONVERGENCE EPISODE 40: 0.0008 rad
2025-08-16 11:22:00,630 - INFO - CONVERGENCE EPISODE 41: 0.0437 rad
2025-08-16 11:22:01,493 - INFO - CONVERGENCE EPISODE 42: 0.0021 rad
2025-08-16 11:22:03,148 - INFO - CONVERGENCE EPISODE 43: 0.4468 rad
2025-08-16 11:22:03,667 - INFO - CONVERGENCE EPISODE 44: 0.0009 rad
2025-08-16 11:22:05,286 - INFO - CONVERGENCE EPISODE 45: 0.0603 rad
2025-08-16 11:22:06,290 - INFO - CONVERGENCE EPISODE 46: 0.0028 rad
2025-08-16 11:22:06,322 - INFO - CONVERGENCE EPISODE 47: 0.0016 rad
2025-08-16 11:22:07,747 - INFO - CONVERGENCE EPISODE 48: 0.0020 rad
2025-08-16 11:22:08,989 - INFO - CONVERGENCE EPISODE 49: 0.0030 rad
2025-08-16 11:22:10,428 - INFO - CONVERGENCE EPISODE 50: 0.0007 rad
2025-08-16 11:22:10,428 - INFO -      50 | -98578.02 | 25763683.518 |    0.0007 |   0.000 |   52.8s
2025-08-16 11:22:10,738 - INFO - CONVERGENCE EPISODE 51: 0.0003 rad
2025-08-16 11:22:11,721 - INFO - CONVERGENCE EPISODE 52: 0.0010 rad
2025-08-16 11:22:13,829 - INFO - CONVERGENCE EPISODE 53: 0.2782 rad
2025-08-16 11:22:14,161 - INFO - CONVERGENCE EPISODE 54: 0.0005 rad
2025-08-16 11:22:14,349 - INFO - CONVERGENCE EPISODE 55: 0.0017 rad
2025-08-16 11:22:14,792 - INFO - CONVERGENCE EPISODE 56: 0.0017 rad
2025-08-16 11:22:15,291 - INFO - CONVERGENCE EPISODE 57: 0.0011 rad
2025-08-16 11:22:15,556 - INFO - CONVERGENCE EPISODE 58: 0.0020 rad
2025-08-16 11:22:16,314 - INFO - CONVERGENCE EPISODE 59: 0.0026 rad
